{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e139d55",
   "metadata": {},
   "source": [
    "## 1. Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e47adee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Buffer distance: 200m\n",
      "âœ“ Bike mode filter: velo\n",
      "âœ“ Silver data: data/silver\n",
      "âœ“ Gold output: data/gold\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from math import radians, sin, cos, sqrt, atan2\n",
    "import os\n",
    "\n",
    "# Load configuration\n",
    "with open(\"../config/config.yml\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Extract key parameters\n",
    "buffer_m = config[\"params\"][\"buffer_m\"]\n",
    "bike_mode = config[\"filters\"][\"bike_mode_value\"]\n",
    "silver_dir = config[\"paths\"][\"silver_dir\"]\n",
    "gold_dir = config[\"paths\"][\"gold_dir\"]\n",
    "\n",
    "print(f\"âœ“ Buffer distance: {buffer_m}m\")\n",
    "print(f\"âœ“ Bike mode filter: {bike_mode}\")\n",
    "print(f\"âœ“ Silver data: {silver_dir}\")\n",
    "print(f\"âœ“ Gold output: {gold_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9519722f",
   "metadata": {},
   "source": [
    "## 2. Create Mock Silver Data\n",
    "\n",
    "Using pandas DataFrames (same schema as PySpark version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bfe540d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Created mock silver_amenagements (3 rows)\n",
      "  amenagement_id  annee_livraison type_amenagement environnement  longueur_m  \\\n",
      "0       AMEN_001             2020   Piste cyclable        Urbain       500.0   \n",
      "1       AMEN_002             2021   Bande cyclable    PÃ©riurbain       300.0   \n",
      "2       AMEN_003             2019       Voie verte        Urbain       800.0   \n",
      "\n",
      "                                 geom_wkt  centroid_lat  centroid_lon  \\\n",
      "0  LINESTRING(4.835 45.764, 4.836 45.765)        45.764         4.835   \n",
      "1  LINESTRING(4.840 45.770, 4.841 45.771)        45.770         4.840   \n",
      "2  LINESTRING(4.850 45.750, 4.851 45.751)        45.750         4.850   \n",
      "\n",
      "        commune  \n",
      "0          Lyon  \n",
      "1  Villeurbanne  \n",
      "2          Lyon  \n"
     ]
    }
   ],
   "source": [
    "# Mock silver_amenagements (infrastructure)\n",
    "mock_amenagements = pd.DataFrame([\n",
    "    {\"amenagement_id\": \"AMEN_001\", \"annee_livraison\": 2020, \"type_amenagement\": \"Piste cyclable\",\n",
    "     \"environnement\": \"Urbain\", \"longueur_m\": 500.0,\n",
    "     \"geom_wkt\": \"LINESTRING(4.835 45.764, 4.836 45.765)\",\n",
    "     \"centroid_lat\": 45.764, \"centroid_lon\": 4.835, \"commune\": \"Lyon\"},\n",
    "    {\"amenagement_id\": \"AMEN_002\", \"annee_livraison\": 2021, \"type_amenagement\": \"Bande cyclable\",\n",
    "     \"environnement\": \"PÃ©riurbain\", \"longueur_m\": 300.0,\n",
    "     \"geom_wkt\": \"LINESTRING(4.840 45.770, 4.841 45.771)\",\n",
    "     \"centroid_lat\": 45.770, \"centroid_lon\": 4.840, \"commune\": \"Villeurbanne\"},\n",
    "    {\"amenagement_id\": \"AMEN_003\", \"annee_livraison\": 2019, \"type_amenagement\": \"Voie verte\",\n",
    "     \"environnement\": \"Urbain\", \"longueur_m\": 800.0,\n",
    "     \"geom_wkt\": \"LINESTRING(4.850 45.750, 4.851 45.751)\",\n",
    "     \"centroid_lat\": 45.750, \"centroid_lon\": 4.850, \"commune\": \"Lyon\"},\n",
    "])\n",
    "\n",
    "print(f\"âœ“ Created mock silver_amenagements ({len(mock_amenagements)} rows)\")\n",
    "print(mock_amenagements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70a51e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Created mock silver_sites (3 rows)\n",
      "    site_id     lat    lon       commune\n",
      "0  SITE_001  45.764  4.835          Lyon\n",
      "1  SITE_002  45.770  4.840  Villeurbanne\n",
      "2  SITE_003  45.780  4.860  Villeurbanne\n"
     ]
    }
   ],
   "source": [
    "# Mock silver_sites (counter locations)\n",
    "mock_sites = pd.DataFrame([\n",
    "    {\"site_id\": \"SITE_001\", \"lat\": 45.764, \"lon\": 4.835, \"commune\": \"Lyon\"},  # Near AMEN_001\n",
    "    {\"site_id\": \"SITE_002\", \"lat\": 45.770, \"lon\": 4.840, \"commune\": \"Villeurbanne\"},  # Near AMEN_002\n",
    "    {\"site_id\": \"SITE_003\", \"lat\": 45.780, \"lon\": 4.860, \"commune\": \"Villeurbanne\"},  # Far from all\n",
    "])\n",
    "\n",
    "print(f\"âœ“ Created mock silver_sites ({len(mock_sites)} rows)\")\n",
    "print(mock_sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66c31ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Created mock silver_channels (5 rows)\n",
      "  channel_id   site_id     mode   sens\n",
      "0   CHAN_001  SITE_001     velo   Nord\n",
      "1   CHAN_002  SITE_001     velo    Sud\n",
      "2   CHAN_003  SITE_002     velo    Est\n",
      "3   CHAN_004  SITE_003     velo  Ouest\n",
      "4   CHAN_005  SITE_002  voiture   Nord\n"
     ]
    }
   ],
   "source": [
    "# Mock silver_channels (counter channels)\n",
    "mock_channels = pd.DataFrame([\n",
    "    {\"channel_id\": \"CHAN_001\", \"site_id\": \"SITE_001\", \"mode\": \"velo\", \"sens\": \"Nord\"},\n",
    "    {\"channel_id\": \"CHAN_002\", \"site_id\": \"SITE_001\", \"mode\": \"velo\", \"sens\": \"Sud\"},\n",
    "    {\"channel_id\": \"CHAN_003\", \"site_id\": \"SITE_002\", \"mode\": \"velo\", \"sens\": \"Est\"},\n",
    "    {\"channel_id\": \"CHAN_004\", \"site_id\": \"SITE_003\", \"mode\": \"velo\", \"sens\": \"Ouest\"},\n",
    "    {\"channel_id\": \"CHAN_005\", \"site_id\": \"SITE_002\", \"mode\": \"voiture\", \"sens\": \"Nord\"},  # Non-bike\n",
    "])\n",
    "\n",
    "print(f\"âœ“ Created mock silver_channels ({len(mock_channels)} rows)\")\n",
    "print(mock_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b72e7c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Created mock silver_measures (120 rows)\n",
      "            flux      \n",
      "           count   sum\n",
      "channel_id            \n",
      "CHAN_001      30  5370\n",
      "CHAN_002      30  3435\n",
      "CHAN_003      30  8805\n",
      "CHAN_004      30  2685\n"
     ]
    }
   ],
   "source": [
    "# Mock silver_measures (time-series counts)\n",
    "base_date = datetime(2023, 6, 1)\n",
    "mock_data = []\n",
    "\n",
    "for day in range(30):\n",
    "    current_date = (base_date + timedelta(days=day)).date()\n",
    "    # CHAN_001: 100-200 bikes/day\n",
    "    mock_data.append({\"channel_id\": \"CHAN_001\", \"date\": current_date, \"flux\": 150 + day * 2, \"is_valid\": True})\n",
    "    # CHAN_002: 80-120 bikes/day\n",
    "    mock_data.append({\"channel_id\": \"CHAN_002\", \"date\": current_date, \"flux\": 100 + day, \"is_valid\": True})\n",
    "    # CHAN_003: 200-300 bikes/day\n",
    "    mock_data.append({\"channel_id\": \"CHAN_003\", \"date\": current_date, \"flux\": 250 + day * 3, \"is_valid\": True})\n",
    "    # CHAN_004: 50-100 bikes/day\n",
    "    mock_data.append({\"channel_id\": \"CHAN_004\", \"date\": current_date, \"flux\": 75 + day, \"is_valid\": True})\n",
    "\n",
    "mock_measures = pd.DataFrame(mock_data)\n",
    "\n",
    "print(f\"âœ“ Created mock silver_measures ({len(mock_measures)} rows)\")\n",
    "print(mock_measures.groupby(\"channel_id\").agg({\"flux\": [\"count\", \"sum\"]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333b6d14",
   "metadata": {},
   "source": [
    "## 3. Spatial Join: Link Counters to Infrastructure\n",
    "\n",
    "Use Haversine formula to calculate distances and find nearby counter sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "804e6b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Found 2 amenagement-site pairs within 200m\n",
      "  amenagement_id  centroid_lat  centroid_lon   site_id     lat    lon  \\\n",
      "0       AMEN_001        45.764         4.835  SITE_001  45.764  4.835   \n",
      "4       AMEN_002        45.770         4.840  SITE_002  45.770  4.840   \n",
      "\n",
      "   distance_m  \n",
      "0         0.0  \n",
      "4         0.0  \n"
     ]
    }
   ],
   "source": [
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"Calculate distance in meters between two points\"\"\"\n",
    "    R = 6371000  # Earth radius in meters\n",
    "    \n",
    "    lat1_rad, lon1_rad = radians(lat1), radians(lon1)\n",
    "    lat2_rad, lon2_rad = radians(lat2), radians(lon2)\n",
    "    \n",
    "    dlat = lat2_rad - lat1_rad\n",
    "    dlon = lon2_rad - lon1_rad\n",
    "    \n",
    "    a = sin(dlat/2)**2 + cos(lat1_rad) * cos(lat2_rad) * sin(dlon/2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1-a))\n",
    "    \n",
    "    return R * c\n",
    "\n",
    "# Cross join amenagements and sites\n",
    "cross_join = mock_amenagements[[\"amenagement_id\", \"centroid_lat\", \"centroid_lon\"]].merge(\n",
    "    mock_sites[[\"site_id\", \"lat\", \"lon\"]],\n",
    "    how=\"cross\"\n",
    ")\n",
    "\n",
    "# Calculate distance\n",
    "cross_join[\"distance_m\"] = cross_join.apply(\n",
    "    lambda row: haversine_distance(row[\"centroid_lat\"], row[\"centroid_lon\"], row[\"lat\"], row[\"lon\"]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Filter within buffer\n",
    "df_within_buffer = cross_join[cross_join[\"distance_m\"] <= buffer_m].copy()\n",
    "\n",
    "print(f\"âœ“ Found {len(df_within_buffer)} amenagement-site pairs within {buffer_m}m\")\n",
    "print(df_within_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df5b696e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Found 3 amenagement-channel links (bike mode only)\n",
      "  amenagement_id  centroid_lat  centroid_lon   site_id     lat    lon  \\\n",
      "0       AMEN_001        45.764         4.835  SITE_001  45.764  4.835   \n",
      "1       AMEN_001        45.764         4.835  SITE_001  45.764  4.835   \n",
      "2       AMEN_002        45.770         4.840  SITE_002  45.770  4.840   \n",
      "\n",
      "   distance_m channel_id  mode  sens  \n",
      "0         0.0   CHAN_001  velo  Nord  \n",
      "1         0.0   CHAN_002  velo   Sud  \n",
      "2         0.0   CHAN_003  velo   Est  \n"
     ]
    }
   ],
   "source": [
    "# Join with channels and filter for bike mode\n",
    "df_amen_channels = df_within_buffer.merge(\n",
    "    mock_channels,\n",
    "    on=\"site_id\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "df_amen_channels = df_amen_channels[df_amen_channels[\"mode\"] == bike_mode]\n",
    "\n",
    "print(f\"âœ“ Found {len(df_amen_channels)} amenagement-channel links (bike mode only)\")\n",
    "print(df_amen_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6f7823b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Created gold_link_amenagement_channel (3 rows)\n",
      "  amenagement_id channel_id   site_id  distance_m\n",
      "0       AMEN_001   CHAN_001  SITE_001         0.0\n",
      "1       AMEN_001   CHAN_002  SITE_001         0.0\n",
      "2       AMEN_002   CHAN_003  SITE_002         0.0\n"
     ]
    }
   ],
   "source": [
    "# Create gold_link_amenagement_channel\n",
    "gold_link = df_amen_channels[[\"amenagement_id\", \"channel_id\", \"site_id\", \"distance_m\"]].drop_duplicates()\n",
    "\n",
    "print(f\"âœ“ Created gold_link_amenagement_channel ({len(gold_link)} rows)\")\n",
    "print(gold_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adefcbde",
   "metadata": {},
   "source": [
    "## 4. Aggregate Daily Flows per Infrastructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aaecd51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Joined 90 measure records\n",
      "  amenagement_id channel_id        date  flux\n",
      "0       AMEN_001   CHAN_001  2023-06-01   150\n",
      "1       AMEN_001   CHAN_001  2023-06-02   152\n",
      "2       AMEN_001   CHAN_001  2023-06-03   154\n",
      "3       AMEN_001   CHAN_001  2023-06-04   156\n",
      "4       AMEN_001   CHAN_001  2023-06-05   158\n",
      "5       AMEN_001   CHAN_001  2023-06-06   160\n",
      "6       AMEN_001   CHAN_001  2023-06-07   162\n",
      "7       AMEN_001   CHAN_001  2023-06-08   164\n",
      "8       AMEN_001   CHAN_001  2023-06-09   166\n",
      "9       AMEN_001   CHAN_001  2023-06-10   168\n"
     ]
    }
   ],
   "source": [
    "# Join links with measures\n",
    "df_flows = gold_link.merge(\n",
    "    mock_measures[mock_measures[\"is_valid\"]],\n",
    "    on=\"channel_id\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "print(f\"âœ“ Joined {len(df_flows)} measure records\")\n",
    "print(df_flows[[\"amenagement_id\", \"channel_id\", \"date\", \"flux\"]].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77485a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Created gold_flow_amenagement_daily (60 rows)\n",
      "   amenagement_id        date  flux_estime  n_channels\n",
      "0        AMEN_001  2023-06-01          250           2\n",
      "1        AMEN_001  2023-06-02          253           2\n",
      "2        AMEN_001  2023-06-03          256           2\n",
      "3        AMEN_001  2023-06-04          259           2\n",
      "4        AMEN_001  2023-06-05          262           2\n",
      "5        AMEN_001  2023-06-06          265           2\n",
      "6        AMEN_001  2023-06-07          268           2\n",
      "7        AMEN_001  2023-06-08          271           2\n",
      "8        AMEN_001  2023-06-09          274           2\n",
      "9        AMEN_001  2023-06-10          277           2\n",
      "10       AMEN_001  2023-06-11          280           2\n",
      "11       AMEN_001  2023-06-12          283           2\n",
      "12       AMEN_001  2023-06-13          286           2\n",
      "13       AMEN_001  2023-06-14          289           2\n",
      "14       AMEN_001  2023-06-15          292           2\n",
      "15       AMEN_001  2023-06-16          295           2\n",
      "16       AMEN_001  2023-06-17          298           2\n",
      "17       AMEN_001  2023-06-18          301           2\n",
      "18       AMEN_001  2023-06-19          304           2\n",
      "19       AMEN_001  2023-06-20          307           2\n"
     ]
    }
   ],
   "source": [
    "# Aggregate by amenagement_id and date\n",
    "gold_flow_daily = df_flows.groupby([\"amenagement_id\", \"date\"]).agg(\n",
    "    flux_estime=(\"flux\", \"sum\"),\n",
    "    n_channels=(\"channel_id\", \"nunique\")\n",
    ").reset_index().sort_values([\"amenagement_id\", \"date\"])\n",
    "\n",
    "print(f\"âœ“ Created gold_flow_amenagement_daily ({len(gold_flow_daily)} rows)\")\n",
    "print(gold_flow_daily.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa3cc6d",
   "metadata": {},
   "source": [
    "## 5. Data Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83a6099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ No duplicate links\n",
      "âœ“ 2 amenagements with flow data\n",
      "âœ“ All flux values are non-negative\n",
      "âœ“ All days have at least 1 channel\n",
      "\n",
      "ðŸŽ‰ All quality checks passed!\n"
     ]
    }
   ],
   "source": [
    "# Check 1: No duplicate amenagement-channel links\n",
    "duplicates = gold_link.groupby([\"amenagement_id\", \"channel_id\"]).size()\n",
    "assert (duplicates == 1).all(), \"FAILED: Found duplicate amenagement-channel links\"\n",
    "print(\"âœ“ No duplicate links\")\n",
    "\n",
    "# Check 2: All amenagements with data\n",
    "amen_with_data = gold_flow_daily[\"amenagement_id\"].nunique()\n",
    "print(f\"âœ“ {amen_with_data} amenagements with flow data\")\n",
    "\n",
    "# Check 3: flux_estime should be non-negative\n",
    "assert (gold_flow_daily[\"flux_estime\"] >= 0).all(), \"FAILED: Found negative flux values\"\n",
    "print(\"âœ“ All flux values are non-negative\")\n",
    "\n",
    "# Check 4: n_channels should be >= 1\n",
    "assert (gold_flow_daily[\"n_channels\"] >= 1).all(), \"FAILED: Found days with 0 channels\"\n",
    "print(\"âœ“ All days have at least 1 channel\")\n",
    "\n",
    "print(\"\\n All quality checks passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b368b072",
   "metadata": {},
   "source": [
    "## 6. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96cb035e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary by infrastructure:\n",
      "  amenagement_id  total_days  total_flux  avg_daily_flux  max_channels\n",
      "0       AMEN_001          30        8805           293.5             2\n",
      "1       AMEN_002          30        8805           293.5             1\n"
     ]
    }
   ],
   "source": [
    "# Summary by amenagement\n",
    "summary = gold_flow_daily.groupby(\"amenagement_id\").agg(\n",
    "    total_days=(\"date\", \"count\"),\n",
    "    total_flux=(\"flux_estime\", \"sum\"),\n",
    "    avg_daily_flux=(\"flux_estime\", \"mean\"),\n",
    "    max_channels=(\"n_channels\", \"max\")\n",
    ").reset_index().sort_values(\"avg_daily_flux\", ascending=False)\n",
    "\n",
    "print(\"Summary by infrastructure:\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cfaab4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Daily flows for AMEN_001:\n",
      "  amenagement_id        date  flux_estime  n_channels\n",
      "0       AMEN_001  2023-06-01          250           2\n",
      "1       AMEN_001  2023-06-02          253           2\n",
      "2       AMEN_001  2023-06-03          256           2\n",
      "3       AMEN_001  2023-06-04          259           2\n",
      "4       AMEN_001  2023-06-05          262           2\n",
      "5       AMEN_001  2023-06-06          265           2\n",
      "6       AMEN_001  2023-06-07          268           2\n",
      "7       AMEN_001  2023-06-08          271           2\n",
      "8       AMEN_001  2023-06-09          274           2\n",
      "9       AMEN_001  2023-06-10          277           2\n"
     ]
    }
   ],
   "source": [
    "# Daily flows for AMEN_001\n",
    "print(\"\\nDaily flows for AMEN_001:\")\n",
    "print(gold_flow_daily[gold_flow_daily[\"amenagement_id\"] == \"AMEN_001\"].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3ac1e1",
   "metadata": {},
   "source": [
    "## 7. Save Outputs (CSV format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bbac822a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ All files saved to CSV format\n",
      "   Silver: data/silver/\n",
      "   Gold: data/gold/\n"
     ]
    }
   ],
   "source": [
    "# Create output directories\n",
    "os.makedirs(f\"../{silver_dir}\", exist_ok=True)\n",
    "os.makedirs(f\"../{gold_dir}\", exist_ok=True)\n",
    "\n",
    "# Save Silver mock data\n",
    "mock_amenagements.to_csv(f\"../{silver_dir}/silver_amenagements.csv\", index=False)\n",
    "mock_sites.to_csv(f\"../{silver_dir}/silver_sites.csv\", index=False)\n",
    "mock_channels.to_csv(f\"../{silver_dir}/silver_channels.csv\", index=False)\n",
    "mock_measures.to_csv(f\"../{silver_dir}/silver_measures.csv\", index=False)\n",
    "\n",
    "# Save Gold outputs\n",
    "gold_link.to_csv(f\"../{gold_dir}/gold_link_amenagement_channel.csv\", index=False)\n",
    "gold_flow_daily.to_csv(f\"../{gold_dir}/gold_flow_amenagement_daily.csv\", index=False)\n",
    "\n",
    "print(\"âœ“ All files saved to CSV format\")\n",
    "print(f\"   Silver: {silver_dir}/\")\n",
    "print(f\"   Gold: {gold_dir}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce55acdb",
   "metadata": {},
   "source": [
    "## 8. Next Steps\n",
    "\n",
    "âœ… **Module 2 Logic Complete** â€” All spatial joins and aggregations work!\n",
    "\n",
    "**Migration to PySpark (when needed):**\n",
    "```python\n",
    "# Pandas â†’ PySpark conversion is straightforward:\n",
    "df_spark = spark.createDataFrame(df_pandas)\n",
    "\n",
    "# Most operations map directly:\n",
    "# pandas: df.merge()        â†’ PySpark: df.join()\n",
    "# pandas: df.groupby()      â†’ PySpark: df.groupBy()\n",
    "# pandas: df.apply()        â†’ PySpark: @udf or built-in functions\n",
    "```\n",
    "\n",
    "**When Module 1 delivers real data:**\n",
    "1. If data is small (<1GB): Continue with pandas\n",
    "2. If data is large: Convert to PySpark using the logic you've developed here\n",
    "3. Run on Linux or properly configured Spark environment\n",
    "\n",
    "**Share with colleagues:**\n",
    "- The [docs/module2_requirements.md](../docs/module2_requirements.md) specifies your data needs\n",
    "- The CSV outputs show expected schema and sample data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
