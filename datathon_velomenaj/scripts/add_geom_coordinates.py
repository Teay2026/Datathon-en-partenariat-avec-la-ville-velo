"""
Script: Ajouter les coordonnÃ©es gÃ©omÃ©triques aux amÃ©nagements
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Input:
  - data/silver/silver_amenagements/ (Parquet)
  - data/bronze/metropole-de-lyon_pvo_patrimoine_voirie.pvoamenagementcyclable.json
  
Output:
  - data/silver/silver_amenagements_with_coordinates/ (Parquet)
  
Nouvelle colonne:
  - coordiantes: string JSON contenant [[lon, lat], [lon, lat], ...]
"""

import json
import yaml
import pandas as pd
from pyspark.sql import SparkSession
from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 1. CONFIGURATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Chargement config
with open("config/config.yml") as f:
    config = yaml.safe_load(f)

BRONZE_DIR = config["paths"]["bronze_dir"]
SILVER_DIR = config["paths"]["silver_dir"]

INPUT_PARQUET = f"{SILVER_DIR}/silver_amenagements"
INPUT_JSON = f"{BRONZE_DIR}/metropole-de-lyon_pvo_patrimoine_voirie.pvoamenagementcyclable.json"
OUTPUT_PARQUET = f"{SILVER_DIR}/silver_amenagements_with_coordinates"

print("="*70)
print("ğŸš´ EXTRACTION DES COORDONNÃ‰ES GÃ‰OMÃ‰TRIQUES")
print("="*70)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 2. INITIALISATION SPARK
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

spark = SparkSession.builder \
    .appName("AddGeometryCoordinates") \
    .config("spark.sql.adaptive.enabled", "true") \
    .getOrCreate()

print("\nâœ“ Spark session initialized")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 3. CHARGEMENT DES DONNÃ‰ES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Charger le Parquet en Pandas
df_amenagements = spark.read.parquet(INPUT_PARQUET).toPandas()
print(f"âœ“ Loaded Parquet: {len(df_amenagements):,} amenagements")
print(f"  Columns: {list(df_amenagements.columns)}")

# Charger le JSON
print(f"\nâœ“ Loading GeoJSON: {INPUT_JSON}")
with open(INPUT_JSON, 'r', encoding='utf-8') as f:
    geojson_data = json.load(f)

print(f"âœ“ Loaded {len(geojson_data['features'])} features from GeoJSON")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 4. CRÃ‰ER UN DICTIONNAIRE GID â†’ COORDONNÃ‰ES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def extract_coordinates_from_multilinestring(geometry):
    """
    Extrait toutes les coordonnÃ©es d'un MultiLineString.
    Retourne une liste de listes: [[[lon, lat], [lon, lat], ...], [[lon, lat], ...]]
    """
    if geometry is None or geometry.get('type') != 'MultiLineString':
        return None
    
    # MultiLineString contient plusieurs LineStrings
    # Chaque LineString est une liste de coordonnÃ©es [lon, lat]
    coordinates = geometry.get('coordinates', [])
    
    # On retourne directement la liste de segments
    # Format: [[[lon1, lat1], [lon2, lat2], ...], [[lon3, lat3], ...]]
    return coordinates

# Construire le dictionnaire gid â†’ (nom, coordonnÃ©es_json)
geom_dict = {}

for feature in geojson_data['features']:
    gid = feature['properties'].get('gid')
    nom = feature['properties'].get('nom', '')
    geometry = feature.get('geometry')
    
    if gid is not None:
        coords = extract_coordinates_from_multilinestring(geometry)
        if coords:
            # Convertir en JSON string
            coords_json = json.dumps(coords, ensure_ascii=False)
            geom_dict[gid] = {
                'nom': nom,
                'coordiantes': coords_json
            }

print(f"âœ“ Extracted coordinates for {len(geom_dict):,} features")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 5. AJOUTER LA COLONNE AVEC PANDAS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("\nâœ“ Adding 'coordiantes' column...")

def get_coordinates_for_row(row):
    """Obtenir les coordonnÃ©es pour un amÃ©nagement donnÃ©."""
    amenagement_id = row['amenagement_id']
    
    # Essayer de convertir en int
    try:
        gid = int(amenagement_id)
    except (ValueError, TypeError):
        gid = amenagement_id
    
    if gid in geom_dict:
        return geom_dict[gid]['coordiantes']
    return None

# Appliquer la fonction Ã  chaque ligne
df_amenagements['coordiantes'] = df_amenagements.apply(get_coordinates_for_row, axis=1)

# Statistiques
total_count = len(df_amenagements)
coords_count = df_amenagements['coordiantes'].notna().sum()
missing_count = total_count - coords_count

print(f"\nğŸ“Š Statistiques:")
print(f"  â€¢ Total amÃ©nagements: {total_count:,}")
print(f"  â€¢ Avec coordonnÃ©es: {coords_count:,} ({coords_count/total_count*100:.1f}%)")
print(f"  â€¢ Sans coordonnÃ©es: {missing_count:,} ({missing_count/total_count*100:.1f}%)")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 6. SAUVEGARDER LE RÃ‰SULTAT
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print(f"\nâœ“ Saving to: {OUTPUT_PARQUET}")

# S'assurer que la colonne coordiantes est bien de type string
# Forcer explicitement le type pour Ã©viter toute troncature
df_amenagements['coordiantes'] = df_amenagements['coordiantes'].astype(str)

# VÃ©rifier avant sauvegarde
print(f"  VÃ©rification avant sauvegarde:")
sample_check = df_amenagements[df_amenagements['coordiantes'].notna()].iloc[0]
coords_len = len(sample_check['coordiantes'])
print(f"  Exemple longueur: {coords_len} caractÃ¨res")
if coords_len < 100:
    print(f"  âš ï¸ ATTENTION: Longueur suspecte!")

# Sauvegarder directement en Parquet avec Pandas
# Utiliser compression 'snappy' pour Ã©viter les problÃ¨mes de troncature
df_amenagements.to_parquet(
    OUTPUT_PARQUET, 
    engine='pyarrow', 
    index=False,
    compression='snappy'
)

print(f"âœ“ Saved successfully!")
print(f"  â†’ Columns: {list(df_amenagements.columns)}")

# VÃ©rification post-sauvegarde
print(f"\nğŸ” VÃ©rification post-sauvegarde:")
df_verify = pd.read_parquet(OUTPUT_PARQUET)
sample_verify = df_verify[df_verify['coordiantes'].notna()].iloc[0]
verify_len = len(sample_verify['coordiantes'])
print(f"  Longueur aprÃ¨s lecture: {verify_len} caractÃ¨res")

if verify_len == coords_len:
    print(f"  âœ… DonnÃ©es intactes aprÃ¨s sauvegarde!")
else:
    print(f"  âŒ PROBLÃˆME: Troncature dÃ©tectÃ©e ({coords_len} â†’ {verify_len})")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 7. VÃ‰RIFICATION & APERÃ‡U
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("\n" + "="*70)
print("ğŸ” APERÃ‡U DES RÃ‰SULTATS")
print("="*70)

# Montrer quelques exemples avec coordonnÃ©es
sample_with_coords = df_amenagements[df_amenagements['coordiantes'].notna()].head(3)

print("\nâœ… Exemples avec coordonnÃ©es:")
for idx, row in sample_with_coords.iterrows():
    print(f"\n  ID: {row['amenagement_id']}")
    print(f"  Nom: {row['nom']}")
    print(f"  Longueur string JSON: {len(row['coordiantes'])} caractÃ¨res")
    
    # VÃ©rifier que le JSON est valide et complet
    try:
        coords_parsed = json.loads(row['coordiantes'])
        total_points = sum(len(segment) for segment in coords_parsed)
        print(f"  Nombre de segments: {len(coords_parsed)}")
        print(f"  Nombre total de points: {total_points}")
        
        # VÃ©rifier la complÃ©tude
        if row['coordiantes'].endswith('...'):
            print(f"  âŒ ATTENTION: DonnÃ©es tronquÃ©es!")
        else:
            print(f"  âœ… JSON complet et valide")
            
        # Afficher preview court
        coords_preview = row['coordiantes'][:100] + "..." if len(row['coordiantes']) > 100 else row['coordiantes']
        print(f"  Preview: {coords_preview}")
    except json.JSONDecodeError as e:
        print(f"  âŒ ERREUR JSON: {e}")
        print(f"  Derniers caractÃ¨res: ...{row['coordiantes'][-50:]}")
        pass

# Montrer les amÃ©nagements sans coordonnÃ©es
if missing_count > 0:
    print("\nâš ï¸ Exemples SANS coordonnÃ©es:")
    sample_missing = df_amenagements[df_amenagements['coordiantes'].isna()].head(5)
    for idx, row in sample_missing.iterrows():
        print(f"  ID: {row['amenagement_id']}, Nom: {row['nom']}")

print("\n" + "="*70)
print("âœ… TERMINÃ‰")
print("="*70)
print(f"\nğŸ“ Fichier de sortie: {OUTPUT_PARQUET}")
print(f"ğŸ“Š {coords_count:,}/{total_count:,} amÃ©nagements avec coordonnÃ©es")

spark.stop()
